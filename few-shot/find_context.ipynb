{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf882fd-53c5-4272-a98c-9549e59b9d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import time\n",
    "from zss import simple_distance, Node\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215fcb9b-e976-4531-b175-f1079b78f03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633 torch.Size([633, 768]) 1266\n"
     ]
    }
   ],
   "source": [
    "#主要任务是根据策略筛选出合适的上下文，先读取数据\n",
    "with open('../data/carb/carb_50_tree.json','r') as f:\n",
    "    tree_50=json.load(f)\n",
    "with open('../data/carb/carb_dev_tree.json','r') as f:\n",
    "    tree_dev=json.load(f)\n",
    "\n",
    "tensor_50=torch.load('../data/carb/carb_50_tensor.pkl')\n",
    "tensor_dev=torch.load('../data/carb/carb_dev_tensor.pkl')\n",
    "\n",
    "with open('../data/carb/carb_dev_tsv.txt','r') as f:\n",
    "    tsv_data=f.readlines()\n",
    "\n",
    "print(len(tree_dev),tensor_dev.size(),len(tsv_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d669d1-8bbc-4241-95ab-df812fa601a3",
   "metadata": {},
   "source": [
    "def find_index(sent_tags,num,sent):\n",
    "    num_list,word_list=[],[]\n",
    "    for i in range(len(sent_tags)):\n",
    "        if sent_tags[i]==num:\n",
    "            word_list.append(sent[i])\n",
    "            num_list.append(i)\n",
    "    return num_list,word_list\n",
    "\n",
    "with open('../../MyORE/datasets/LSOIE/dev_all.json','r') as f:\n",
    "    tsv_data=json.load(f)\n",
    "\n",
    "sent_list,triple_list=[],[]\n",
    "with open('../data/LSOIE_dev_tsv.txt','w') as f:\n",
    "    for data in tsv_data:\n",
    "        sent=' '.join(data['sent'])\n",
    "        sent_list.append(sent)\n",
    "        f.write('Sentence: '+sent+'\\n')\n",
    "        triple=''\n",
    "        for i in range(len(data['tags'])):\n",
    "            sub=' '.join(data['sent'][data['a1_tags'][i][0]:data['a1_tags'][i][-1]])\n",
    "            obj=' '.join(data['sent'][data['a2_tags'][i][0]:data['a2_tags'][i][-1]]) \n",
    "            _,rel=find_index(data['tags'][i],5,data['sent'])\n",
    "            triple+='<'+sub+'|'+' '.join(rel)+'|'+obj+'>;'\n",
    "        f.write('Triples: '+triple+'\\n')\n",
    "        triple_list.append(triple)\n",
    "print(len(triple_list),len(sent_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6c49b-eabf-4d84-a257-3432361a4eb0",
   "metadata": {},
   "source": [
    "#这儿稍微处理一下，把它变成，一行句子，第二行对应的三元组关系的txt\n",
    "with open('../../openie6-master/carb/data/gold/dev.tsv','r') as f:\n",
    "    tsv_data=f.readlines()\n",
    "sent_list,triple_list,triple,old_sent=[],[],'',tsv_data[0].split('\\t')[0]\n",
    "for data in tsv_data:\n",
    "    if len(data.split('\\t'))>3:\n",
    "        sent=data.split('\\t')[0]\n",
    "        if sent != old_sent:\n",
    "            sent_list.append(old_sent)\n",
    "            triple_list.append(triple)\n",
    "            triple=''\n",
    "            old_sent=sent\n",
    "        rel=data.split('\\t')[1]\n",
    "        sub=data.split('\\t')[2]\n",
    "        obj=data.split('\\t')[3][:-1]\n",
    "        temp_triple='<'+sub+'|'+rel+'|'+obj+'>'\n",
    "        if temp_triple not in triple:              #防止偶尔有特殊情况\n",
    "            triple+=temp_triple+';'\n",
    "    if data==tsv_data[-1]:\n",
    "        sent_list.append(sent)\n",
    "        triple_list.append(triple)\n",
    "print(len(sent_list),len(triple_list))\n",
    "#测试通过\n",
    "with open('../data/carb_dev_tsv.txt','w') as f:\n",
    "    for i in range(len(sent_list)):\n",
    "        if '(' in sent_list[i]:\n",
    "            continue\n",
    "        f.write('Sentence: '+sent_list[i]+'\\n')\n",
    "        f.write('Triples: '+triple_list[i]+'\\n')\n",
    "#测试通过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7665837b-a754-40a6-8d99-c7fbf72a24ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_similar(data_50,data_dev):                   #我想得到一个50,dev_num的张量，然后每个值都代表i，j句子的相似性\n",
    "    result=torch.zeros(data_50.size()[0],data_dev.size()[0])\n",
    "    for i in range(len(data_50)):\n",
    "        for j in range(len(data_dev)):\n",
    "            result[i,j]=torch.cosine_similarity(data_50[i],data_dev[j],dim=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92e68e0d-ec5a-4afd-85ad-c966b427972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(tree_dev,similar_tensor,tsv_data,topk_num=8,TED=False):\n",
    "    if TED:\n",
    "        prob,position=torch.topk(similar_tensor,topk_num,dim=1,largest=False)\n",
    "    else:\n",
    "        prob,position=torch.topk(similar_tensor,topk_num,dim=1)       #50,6的张量，position代表位置，prob代表概率！\n",
    "    context=[]\n",
    "    for i in range(len(position)):\n",
    "        temp_context=[]\n",
    "        for j in range(len(position[i])):\n",
    "            sent=' '.join(tree_dev[position[i][j]]['tokens'])\n",
    "            for h in range(len(tsv_data)):\n",
    "                if sent==tsv_data[h][10:-1]:\n",
    "                    temp_context.append(tsv_data[h]+tsv_data[h+1])\n",
    "        context.append(temp_context)                       #上面是对每个position的句子找context，这个是把8个sample全找到\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420fb877-d8d1-4332-b720-a2686416fc73",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#print(len(tsv_data))\n",
    "similar_test=get_bert_similar(tensor_50,tensor_dev)\n",
    "#print(similar_test.size(),similar_test)\n",
    "%time test=get_context(tree_dev,similar_test,tsv_data)\n",
    "with open('../data/LSOIE/LSOIE_context_byBERT.txt','w') as f:\n",
    "    for data in test:\n",
    "        f.writelines(data)\n",
    "        f.write('\\n')\n",
    "#没找到写入文件的方法，退而求其次，只能用空行来区分了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c021b3-c036-4305-8219-83d43a3dcee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#上面就是基于相似性的跑完了，然后得考虑基于树的\n",
    "def get_constituency_similar(tree_data,tree_dev):\n",
    "    similar_tensor=torch.zeros(len(tree_data),len(tree_dev))\n",
    "    TED_tensor=torch.zeros(len(tree_data),len(tree_dev))\n",
    "    tree_50_list,tree_dev_list,num_50,num_dev=[],[],[],[]\n",
    "    for num,data in enumerate(tree_data):\n",
    "        temp_tree_50,temp_50_num=utils.get_constituency_tree(data['stanford_constituency_tree'][0])\n",
    "        tree_50_list.append(temp_tree_50)\n",
    "        num_50.append(temp_50_num)\n",
    "        print('tree_50:',num)\n",
    "    print('Tree 50 data done!')\n",
    "    for num,data in enumerate(tree_dev):                  #这步很慢，得到100个树\n",
    "        temp_tree_dev, temp_tree_num=utils.get_constituency_tree(data['stanford_constituency_tree'][0])#、\n",
    "        tree_dev_list.append(temp_tree_dev)\n",
    "        num_dev.append(temp_tree_num)\n",
    "        print('tree_dev :',num)\n",
    "    print('Tree dev data done!')\n",
    "\n",
    "    for i in range(len(tree_data)):\n",
    "        for j in range(len(tree_dev)):        \n",
    "            edit_dis=simple_distance(tree_50_list[i], tree_dev_list[j])\n",
    "            print(i,' ',j)\n",
    "            TED_tensor[i][j]=edit_dis\n",
    "            temp_node = num_dev[j] - num_50[i] if num_50[i]<num_dev[j] else 0.5*(num_50[i]-num_dev[j])\n",
    "            tree_similiar=1-(edit_dis+temp_node)/num_50[i]\n",
    "            similar_tensor[i][j]=tree_similiar\n",
    "        print(i,' have done!!!')\n",
    "    return similar_tensor,TED_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d4e5b0-ef94-4d7e-8692-c7d026e0ff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depencey_similar(tree_data,tree_dev):\n",
    "    similar_tensor=torch.zeros(len(tree_data),len(tree_dev))  \n",
    "    TED_tensor=torch.zeros(len(tree_data),len(tree_dev))\n",
    "    tree_50_list,tree_dev_list,num_50,num_dev=[],[],[],[]\n",
    "    index=0\n",
    "    start_time=time.time()\n",
    "    for data in tree_data:\n",
    "        temp_tree_50,temp_50_num=utils.get_depencey_tree(data['dep_graph_edges'])\n",
    "        index+=1\n",
    "        print('tree_50 :',index)\n",
    "        tree_50_list.append(temp_tree_50)\n",
    "        num_50.append(temp_50_num)\n",
    "    print('Tree 50 data done!',time.time()-start_time)\n",
    "    index=0\n",
    "    for data in tree_dev:\n",
    "        temp_tree_dev,temp_dev_num=utils.get_depencey_tree(data['dep_graph_edges'])\n",
    "        tree_dev_list.append(temp_tree_dev)\n",
    "        num_dev.append(temp_dev_num)\n",
    "        index+=1\n",
    "        print('tree_dev :',index)\n",
    "    print('Tree dev data done!')\n",
    "    for i in range(len(tree_data)):\n",
    "        start_time=time.time()\n",
    "        for j in range(len(tree_dev)):        \n",
    "            edit_dis=simple_distance(tree_50_list[i], tree_dev_list[j])     #这步的计算还是挺慢的说实话，一共要50*650个，一个1s的话，也得10多个小时，看看情况吧\n",
    "            TED_tensor[i][j]=edit_dis\n",
    "            print(i,' ',j)\n",
    "            temp_node = num_dev[j] - num_50[i] if num_50[i]<num_dev[j] else 0.5*(num_50[i]-num_dev[j])\n",
    "            tree_similiar=1 - (edit_dis+temp_node)/num_50[i]\n",
    "            similar_tensor[i][j]=tree_similiar\n",
    "        print(i,time.time()-start_time)\n",
    "\n",
    "    return similar_tensor,TED_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31e486-1000-4278-a92a-bab3010b75b5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "del tree_dev[480]\n",
    "#carb数据集编号480的成分树过于复杂\n",
    "%time test_tensor=get_constituency_similar(tree_50,tree_dev)\n",
    "%time test=get_context(tree_dev,test_tensor,tsv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e75f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del tree_dev[815]    \n",
    "#del tree_dev[1131]   \n",
    "#del tree_dev[1668]   \n",
    "#本质就是LSOIE的第815和1132和1670这三个编号的数据太复杂，没法跑，把它们删了\n",
    "del tree_dev[480]\n",
    "%time test_tensor,TED_tensor=get_constituency_similar(tree_50,tree_dev) #这玩意跑了6个h，我服了！\n",
    "%time test=get_context(tree_dev,test_tensor,tsv_data)\n",
    "\n",
    "torch.save(test_tensor,'../data/carb/similiar_tensor_by_consti.pkl')\n",
    "torch.save(TED_tensor,'../data/carb/TED_tensor_by_consti.pkl')\n",
    "with open('../data/carb/carb_context_byConsti.txt','w') as f:\n",
    "    for data in test:\n",
    "        f.writelines(data)\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5363de2-19b5-44ac-99c1-f084a655da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bert_similar,'../data/carb/bert_similar.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08c21987-376a-486d-aa89-251a92a716a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 632])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consti=torch.load('../data/carb/TED_tensor_by_consti.pkl')\n",
    "consti.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d2920d2-cee9-4a12-95b2-913a69f6f5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 632])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new=consti+bert_similar\n",
    "new.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bca8347-195b-4ecb-8952-7faad561a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=get_context(tree_dev,new,tsv_data,TED=True)\n",
    "with open('../data/carb/carb_context_byBertandConsti.txt','w') as f:\n",
    "    for data in test:\n",
    "        f.writelines(data)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436931e-9024-4a23-ad7e-cd698604c131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
